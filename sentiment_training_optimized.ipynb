{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {"provenance": [], "gpuType": "T4"},
    "kernelspec": {"name": "python3", "display_name": "Python 3"},
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": ["# Sentiment Analysis - Target Akurasi > 85%\n\n**Strategi Utama:**\n1. Balanced Dataset dengan Oversampling\n2. Advanced Preprocessing + Slang Normalization\n3. IndoBERT Fine-tuning\n4. Proper Hyperparameters\n\n> Tips bintang 5: pastikan setidaknya 1 eksperimen mendapatkan akurasi train & test > 92%"],
      "metadata": {"id": "header"}
    },
    {
      "cell_type": "code",
      "source": ["!pip -q install transformers datasets evaluate accelerate sentencepiece imbalanced-learn"],
      "metadata": {"id": "install"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": ["import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\nimport re, random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom imblearn.over_sampling import RandomOverSampler\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\n\nDATA_PATH = \"dataset_playstore.csv\""],
      "metadata": {"id": "imports"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## 1) Load Data"],
      "metadata": {"id": "load_header"}
    },
    {
      "cell_type": "code",
      "source": ["df = pd.read_csv(DATA_PATH)\nprint(f\"Total rows: {len(df)}\")\nprint(f\"Columns: {df.columns.tolist()}\")\ndf.head()"],
      "metadata": {"id": "load_data"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## 2) Labeling"],
      "metadata": {"id": "label_header"}
    },
    {
      "cell_type": "code",
      "source": ["def rating_to_label(score):\n    if score <= 2:\n        return \"negatif\"\n    if score == 3:\n        return \"netral\"\n    return \"positif\"\n\nif \"rating\" in df.columns:\n    df[\"rating\"] = df[\"rating\"].fillna(0).astype(int)\n    df[\"label\"] = df[\"rating\"].apply(rating_to_label)\n\ndf[\"label\"] = df[\"label\"].astype(str).str.lower().str.strip()\ndf = df[df[\"label\"].isin([\"negatif\", \"netral\", \"positif\"])].copy()\n\nprint(\"Distribusi label SEBELUM balancing:\")\nprint(df[\"label\"].value_counts())"],
      "metadata": {"id": "labeling"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## 3) Advanced Text Preprocessing dengan Slang Normalization"],
      "metadata": {"id": "preprocess_header"}
    },
    {
      "cell_type": "code",
      "source": ["SLANG_DICT = {\n    'gak': 'tidak', 'ga': 'tidak', 'gk': 'tidak', 'ngga': 'tidak', 'nggak': 'tidak',\n    'enggak': 'tidak', 'engga': 'tidak', 'tdk': 'tidak', 'tak': 'tidak',\n    'kagak': 'tidak', 'kaga': 'tidak',\n    'yg': 'yang', 'dgn': 'dengan', 'utk': 'untuk', 'bgt': 'sangat',\n    'bngt': 'sangat', 'bngtt': 'sangat', 'banget': 'sangat',\n    'bener': 'benar', 'bnr': 'benar',\n    'tp': 'tapi', 'tpi': 'tapi', 'cuma': 'hanya', 'cm': 'hanya',\n    'krn': 'karena', 'karna': 'karena', 'krna': 'karena',\n    'sm': 'sama', 'sma': 'sama', 'ama': 'sama',\n    'aj': 'saja', 'aja': 'saja', 'doang': 'saja', 'doank': 'saja',\n    'udh': 'sudah', 'udah': 'sudah', 'sdh': 'sudah', 'uda': 'sudah',\n    'blm': 'belum', 'blom': 'belum',\n    'lg': 'lagi', 'lgi': 'lagi',\n    'jg': 'juga', 'jga': 'juga',\n    'klo': 'kalau', 'kalo': 'kalau', 'kl': 'kalau',\n    'gmn': 'bagaimana', 'gimana': 'bagaimana',\n    'knp': 'kenapa', 'knpa': 'kenapa',\n    'dmn': 'dimana',\n    'gtu': 'begitu', 'gitu': 'begitu', 'gt': 'begitu',\n    'gni': 'begini', 'gini': 'begini',\n    'org': 'orang', 'orng': 'orang',\n    'bs': 'bisa', 'bsa': 'bisa',\n    'hrs': 'harus', 'hrus': 'harus',\n    'bnyk': 'banyak', 'byk': 'banyak',\n    'skrg': 'sekarang', 'skrang': 'sekarang', 'skg': 'sekarang',\n    'dr': 'dari', 'dri': 'dari',\n    'sy': 'saya', 'aku': 'saya', 'gw': 'saya', 'gue': 'saya', 'gua': 'saya',\n    'lu': 'kamu', 'lo': 'kamu', 'u': 'kamu',\n    'emg': 'memang', 'emang': 'memang',\n    'bkn': 'bukan', 'bukn': 'bukan',\n    'dl': 'dulu', 'dlu': 'dulu',\n    'nih': 'ini', 'ni': 'ini',\n    'tuh': 'itu', 'tu': 'itu',\n    'apk': 'aplikasi', 'app': 'aplikasi',\n    'hp': 'handphone', 'hape': 'handphone',\n    'bgus': 'bagus', 'bgs': 'bagus', 'bagusss': 'bagus',\n    'mantap': 'bagus', 'mantep': 'bagus', 'mantul': 'bagus', 'mantab': 'bagus',\n    'keren': 'bagus',\n    'jos': 'bagus', 'oke': 'baik', 'ok': 'baik', 'okey': 'baik',\n    'top': 'bagus', 'terbaik': 'sangat bagus',\n    'suka': 'suka', 'ska': 'suka',\n    'senang': 'senang', 'snang': 'senang',\n    'puas': 'puas', 'memuaskan': 'puas',\n    'recommended': 'direkomendasikan', 'rekomended': 'direkomendasikan',\n    'nice': 'bagus', 'good': 'bagus', 'great': 'bagus',\n    'love': 'suka', 'like': 'suka',\n    'perfect': 'sempurna', 'amazing': 'luar biasa',\n    'thx': 'terima kasih', 'thanks': 'terima kasih', 'makasih': 'terima kasih',\n    'jlk': 'jelek', 'jlek': 'jelek', 'jelk': 'jelek', 'jelekk': 'jelek',\n    'ancur': 'hancur', 'hancurr': 'hancur',\n    'parah': 'buruk', 'prah': 'buruk',\n    'lemot': 'lambat', 'lmot': 'lambat', 'lelet': 'lambat',\n    'error': 'rusak', 'eror': 'rusak', 'err': 'rusak',\n    'bug': 'masalah', 'bugs': 'masalah',\n    'lag': 'lambat', 'ngelag': 'lambat', 'lagg': 'lambat',\n    'crash': 'rusak', 'cras': 'rusak',\n    'ribet': 'sulit', 'ruwet': 'sulit',\n    'nyebelin': 'menyebalkan', 'sebel': 'kesal', 'sebal': 'kesal',\n    'kesel': 'kesal', 'ksel': 'kesal',\n    'bosen': 'bosan', 'bosenn': 'bosan',\n    'males': 'malas', 'mls': 'malas',\n    'capek': 'lelah', 'cape': 'lelah', 'cpk': 'lelah',\n    'spam': 'spam', 'spamm': 'spam',\n    'banned': 'diblokir', 'blokir': 'blokir', 'keblokir': 'diblokir',\n    'sampah': 'buruk', 'smph': 'buruk',\n    'bad': 'buruk', 'worst': 'terburuk',\n    'hate': 'benci', 'annoying': 'menyebalkan',\n    'download': 'unduh', 'donlot': 'unduh', 'donlod': 'unduh',\n    'upload': 'unggah', 'uplod': 'unggah',\n    'update': 'perbarui', 'updet': 'perbarui', 'apdet': 'perbarui',\n    'install': 'pasang', 'instal': 'pasang',\n    'uninstall': 'hapus', 'uninsta': 'hapus',\n    'wkwk': '', 'wkwkwk': '', 'wkwkwkwk': '',\n    'haha': '', 'hahaha': '', 'hehe': '', 'hihi': '',\n    'lol': '', 'lmao': '',\n    'btw': '', 'fyi': '',\n    'deh': '', 'dong': '', 'sih': '', 'kok': '', 'loh': '', 'lah': '',\n}\n\ndef clean_text_advanced(text):\n    if not isinstance(text, str):\n        return \"\"\n    text = text.lower()\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', ' ', text)\n    text = re.sub(r'@\\w+|#\\w+', ' ', text)\n    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n    text = re.sub(r'\\d+', ' ', text)\n    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n    words = text.split()\n    words = [SLANG_DICT.get(w, w) for w in words]\n    words = [w for w in words if w.strip()]\n    text = ' '.join(words)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ndf[\"text\"] = df[\"text\"].astype(str)\ndf[\"text_clean\"] = df[\"text\"].apply(clean_text_advanced)\ndf = df[df[\"text_clean\"].str.len() > 2].copy()\n\nprint(\"Contoh hasil preprocessing:\")\nprint(df[[\"text\", \"text_clean\", \"label\"]].sample(5, random_state=SEED))"],
      "metadata": {"id": "preprocessing"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## 4) Balance Dataset dengan Oversampling"],
      "metadata": {"id": "balance_header"}
    },
    {
      "cell_type": "code",
      "source": ["print(\"Distribusi SEBELUM balancing:\")\nprint(df[\"label\"].value_counts())\n\nX = df[\"text_clean\"].values\ny = df[\"label\"].values\n\nlabel_to_id = {\"negatif\": 0, \"netral\": 1, \"positif\": 2}\nid_to_label = {v: k for k, v in label_to_id.items()}\ny_encoded = np.array([label_to_id[l] for l in y])\n\nros = RandomOverSampler(random_state=SEED)\nX_resampled, y_resampled = ros.fit_resample(X.reshape(-1, 1), y_encoded)\nX_resampled = X_resampled.flatten()\n\nprint(\"\\nDistribusi SETELAH balancing:\")\nunique, counts = np.unique(y_resampled, return_counts=True)\nfor u, c in zip(unique, counts):\n    print(f\"  {id_to_label[u]}: {c}\")\nprint(f\"\\nTotal data setelah balancing: {len(X_resampled)}\")"],
      "metadata": {"id": "balancing"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## 5) Train/Test Split"],
      "metadata": {"id": "split_header"}
    },
    {
      "cell_type": "code",
      "source": ["X_train, X_test, y_train, y_test = train_test_split(\n    X_resampled, y_resampled, test_size=0.2, random_state=SEED, stratify=y_resampled\n)\nprint(f\"Training samples: {len(X_train)}\")\nprint(f\"Test samples: {len(X_test)}\")"],
      "metadata": {"id": "split"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["---\n# EKSPERIMEN 1: TF-IDF + SVM (80/20)"],
      "metadata": {"id": "exp1_header"}
    },
    {
      "cell_type": "code",
      "source": ["print(\"=\"*50)\nprint(\"EKSPERIMEN 1: TF-IDF + SVM (80/20)\")\nprint(\"=\"*50)\n\ntfidf_1 = TfidfVectorizer(\n    max_features=10000,\n    ngram_range=(1, 3),\n    min_df=2,\n    max_df=0.95,\n    sublinear_tf=True\n)\n\nX_train_tfidf = tfidf_1.fit_transform(X_train)\nX_test_tfidf = tfidf_1.transform(X_test)\n\nsvm = SVC(\n    kernel='rbf',\n    C=10,\n    gamma='scale',\n    class_weight='balanced',\n    random_state=SEED\n)\n\nsvm.fit(X_train_tfidf, y_train)\n\npred_svm_train = svm.predict(X_train_tfidf)\npred_svm_test = svm.predict(X_test_tfidf)\n\nacc_svm_train = accuracy_score(y_train, pred_svm_train)\nacc_svm_test = accuracy_score(y_test, pred_svm_test)\n\nprint(f\"\\nTrain Accuracy: {acc_svm_train:.4f} ({acc_svm_train*100:.2f}%)\")\nprint(f\"Test Accuracy: {acc_svm_test:.4f} ({acc_svm_test*100:.2f}%)\")\nprint(\"\\nClassification Report (Test):\")\nprint(classification_report(y_test, pred_svm_test, target_names=[\"negatif\", \"netral\", \"positif\"]))"],
      "metadata": {"id": "exp1"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["---\n# EKSPERIMEN 2: TF-IDF + Ensemble Voting (70/30)"],
      "metadata": {"id": "exp2_header"}
    },
    {
      "cell_type": "code",
      "source": ["print(\"=\"*50)\nprint(\"EKSPERIMEN 2: TF-IDF + Ensemble Voting (70/30)\")\nprint(\"=\"*50)\n\nX_train2, X_test2, y_train2, y_test2 = train_test_split(\n    X_resampled, y_resampled, test_size=0.3, random_state=SEED, stratify=y_resampled\n)\n\ntfidf_2 = TfidfVectorizer(\n    max_features=10000,\n    ngram_range=(1, 3),\n    min_df=2,\n    max_df=0.95,\n    sublinear_tf=True\n)\n\nX_train2_tfidf = tfidf_2.fit_transform(X_train2)\nX_test2_tfidf = tfidf_2.transform(X_test2)\n\nensemble = VotingClassifier(\n    estimators=[\n        ('svm', SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=SEED)),\n        ('lr', LogisticRegression(max_iter=1000, C=10, class_weight='balanced', random_state=SEED)),\n        ('rf', RandomForestClassifier(n_estimators=200, max_depth=20, class_weight='balanced', random_state=SEED))\n    ],\n    voting='soft'\n)\n\nensemble.fit(X_train2_tfidf, y_train2)\n\npred_ens_train = ensemble.predict(X_train2_tfidf)\npred_ens_test = ensemble.predict(X_test2_tfidf)\n\nacc_ens_train = accuracy_score(y_train2, pred_ens_train)\nacc_ens_test = accuracy_score(y_test2, pred_ens_test)\n\nprint(f\"\\nTrain Accuracy: {acc_ens_train:.4f} ({acc_ens_train*100:.2f}%)\")\nprint(f\"Test Accuracy: {acc_ens_test:.4f} ({acc_ens_test*100:.2f}%)\")\nprint(\"\\nClassification Report (Test):\")\nprint(classification_report(y_test2, pred_ens_test, target_names=[\"negatif\", \"netral\", \"positif\"]))"],
      "metadata": {"id": "exp2"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["---\n# EKSPERIMEN 3: IndoBERT Fine-tuning (80/20)"],
      "metadata": {"id": "exp3_header"}
    },
    {
      "cell_type": "code",
      "source": ["print(\"=\"*50)\nprint(\"EKSPERIMEN 3: IndoBERT Fine-tuning\")\nprint(\"=\"*50)\n\nfrom datasets import Dataset\nimport evaluate\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding\n)\n\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    X_resampled.tolist(),\n    y_resampled.tolist(),\n    test_size=0.2,\n    random_state=SEED,\n    stratify=y_resampled.tolist()\n)\n\nds_train = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels})\nds_val = Dataset.from_dict({\"text\": val_texts, \"label\": val_labels})\n\nprint(f\"Training samples: {len(ds_train)}\")\nprint(f\"Validation samples: {len(ds_val)}\")"],
      "metadata": {"id": "exp3_setup"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": ["model_name = \"indobenchmark/indobert-base-p2\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef tokenize_fn(batch):\n    return tokenizer(batch[\"text\"], truncation=True, max_length=128)\n\nds_train = ds_train.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\nds_val = ds_val.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n\ncollator = DataCollatorWithPadding(tokenizer=tokenizer)\nprint(\"Tokenization done!\")"],
      "metadata": {"id": "exp3_tokenize"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": ["metric_acc = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    return metric_acc.compute(predictions=preds, references=labels)\n\nbert_model = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=3,\n    id2label=id_to_label,\n    label2id=label_to_id,\n)\n\nargs = TrainingArguments(\n    output_dir=\"bert_out\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    warmup_ratio=0.1,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_accuracy\",\n    logging_steps=100,\n    report_to=\"none\",\n    seed=SEED,\n)\n\ntrainer = Trainer(\n    model=bert_model,\n    args=args,\n    train_dataset=ds_train,\n    eval_dataset=ds_val,\n    processing_class=tokenizer,\n    data_collator=collator,\n    compute_metrics=compute_metrics,\n)\n\nprint(\"Starting IndoBERT training...\")\nprint(\"Estimasi waktu: 15-30 menit di Colab GPU\")\ntrainer.train()"],
      "metadata": {"id": "exp3_train"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": ["res = trainer.evaluate()\nacc_bert = res['eval_accuracy']\n\nprint(\"\\n\" + \"=\"*50)\nprint(f\"IndoBERT Validation Accuracy: {acc_bert:.4f} ({acc_bert*100:.2f}%)\")\nprint(\"=\"*50)"],
      "metadata": {"id": "exp3_eval"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["---\n# RINGKASAN & EVALUASI"],
      "metadata": {"id": "summary_header"}
    },
    {
      "cell_type": "code",
      "source": ["print(\"\\n\" + \"=\"*60)\nprint(\"RINGKASAN HASIL SEMUA EKSPERIMEN\")\nprint(\"=\"*60)\n\nscores = {\n    \"Exp1_TFIDF_SVM_80_20\": acc_svm_test,\n    \"Exp2_TFIDF_Ensemble_70_30\": acc_ens_test,\n    \"Exp3_IndoBERT_80_20\": acc_bert,\n}\n\nprint(\"\\n| Eksperimen | Akurasi Test |\")\nprint(\"|------------|--------------|\")\nfor name, score in scores.items():\n    status = \"OK\" if score >= 0.85 else \"LOW\"\n    print(f\"| {name} | {score*100:.2f}% {status} |\")\n\nbest_exp = max(scores, key=scores.get)\nbest_score = scores[best_exp]\n\nprint(f\"\\nModel Terbaik: {best_exp}\")\nprint(f\"Akurasi: {best_score*100:.2f}%\")\n\nif best_score >= 0.92:\n    print(\"\\nTARGET BINTANG 5 TERCAPAI! (>92%)\")\nelif best_score >= 0.85:\n    print(\"\\nTARGET >85% TERCAPAI!\")\nelse:\n    print(\"\\nPerlu optimasi lebih lanjut\")"],
      "metadata": {"id": "summary"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": ["cm = confusion_matrix(y_test, pred_svm_test)\nlabels = [\"negatif\", \"netral\", \"positif\"]\n\nplt.figure(figsize=(8, 6))\nplt.imshow(cm, cmap='Blues')\nplt.title(f\"Confusion Matrix - {best_exp}\\nAccuracy: {best_score*100:.2f}%\")\nplt.colorbar()\nplt.xticks(range(len(labels)), labels, rotation=45)\nplt.yticks(range(len(labels)), labels)\n\nfor i in range(cm.shape[0]):\n    for j in range(cm.shape[1]):\n        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\",\n                color=\"white\" if cm[i, j] > cm.max()/2 else \"black\")\n\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.tight_layout()\nplt.show()"],
      "metadata": {"id": "confusion_matrix"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["---\n# INFERENCE"],
      "metadata": {"id": "inference_header"}
    },
    {
      "cell_type": "code",
      "source": ["contoh_teks = [\n    \"Aplikasinya sering error dan bikin emosi\",\n    \"Biasa saja, lumayan buat kebutuhan saya\",\n    \"Mantap! Fiturnya lengkap dan sangat membantu\",\n    \"Netral sih, tapi kadang lemot\",\n    \"Iklan kebanyakan, mengganggu banget\",\n    \"Sangat bagus dan mudah digunakan\",\n    \"Jelek banget ga bisa dipake\",\n    \"Oke lah cukup membantu\",\n]\n\nprint(\"=\"*60)\nprint(\"HASIL PREDIKSI SENTIMENT\")\nprint(\"=\"*60)\n\ntexts_clean = [clean_text_advanced(t) for t in contoh_teks]\nX_vec = tfidf_1.transform(texts_clean)\npredictions = svm.predict(X_vec)\n\nfor text, pred in zip(contoh_teks, predictions):\n    label = id_to_label[pred]\n    emoji = \":)\" if label == \"positif\" else \":|\" if label == \"netral\" else \":(\"\n    print(f\"\\nTeks: {text}\")\n    print(f\"Prediksi: {label.upper()} {emoji}\")"],
      "metadata": {"id": "inference"},
      "execution_count": null,
      "outputs": []
    }
  ]
}